# -*- coding: utf-8 -*-
"""Using Machine learning approach Customer Churn predictions for a Telecom Company .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1imL6QiKHHs5ykNuC1k9yFpFKmU8c5LiT

## **A Machine Learning Approach to Predict Customer Churn for a Telecom Compnay Based on User Data Analysis**

This is a Machine learning approach to predict customer churn for next time Service retention for Telecom Company based user data Analysis.It is under Supervised Machine learning problem which is Regression Based.

Behind the Project:

Arfin Shariar (201-15-3316)
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib as mlib
from matplotlib import pyplot as plt

from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.utils import resample
from sklearn.model_selection import train_test_split

from sklearn import metrics
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
from sklearn.ensemble import AdaBoostClassifier
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import VotingClassifier

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

#mounting our google drive
from google.colab import drive
drive.mount('/content/drive')

"""## **Dataset Import**"""

#Dataset Import
df = pd.read_csv("/content/drive/MyDrive/Final Defense/Data/CHURN.csv")

df.head()

df.tail()

"""## **EDA & Feature Importance**"""

print(f"Shape of Dataset: {df.shape}")

df.columns

df.count().sum()

df.dtypes

"""Change Data types of TotalCharges"""

df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')



df.isnull().sum().T

"""There is no Value Missing in our Dataset."""

df.info()

from sklearn.preprocessing import LabelEncoder
L_encoder = LabelEncoder()
df["Churn"] = L_encoder.fit_transform(df["Churn"])

#Let's Explore our Churn value
df["Churn"].value_counts()

sns.countplot(x="Churn",data = df)
plt.title("Distribution of Churn")

"""We clearly seen that our Dataset is in Imbalance Condition. We need to treat our these Imbalance conditions.

Before Treatment we need to find out Catagorical & Numerical Data from our Dataset.
"""

cat_cols = []

for col in df.columns:
  if df[col].dtype == "object":
    cat_cols.append(col)

print("Our Catagorical Columns are: ",format(len(cat_cols)))
cat_cols

"""Now Let's Findout Binary Columns of Dataset"""

bin_col = []

for col in df.columns:
  if df[col].value_counts().shape[0] == 2:
    bin_col.append(col)

print("Our Binary Columns are: ",format(len(bin_col)))
bin_col

"""Let's Check the Distribution of those value using Countplot"""

fig, axes = plt.subplots(2,3, figsize = (12,8), sharey = True)
plt.suptitle("Distribution of binary features")
sns.countplot(x = "gender", data = df, ax=axes[0,0])
sns.countplot(x = "SeniorCitizen", data = df, ax=axes[0,1])
sns.countplot(x = "Partner", data = df, ax=axes[0,2])
sns.countplot(x = "Dependents", data = df, ax=axes[1,0])
sns.countplot(x = "PaperlessBilling", data = df, ax=axes[1,1])
sns.countplot(x = "PhoneService", data = df, ax=axes[1,2])

"""As we can see from the Figure that there is very Significant Imbalance in SeniorCitizen Data, PhoneService Data, Dependents Data.

Affect of These all Variables in Respect to Churn value
"""

df[['gender', 'Churn']].groupby(['gender']).mean()

df[['SeniorCitizen', 'Churn']].groupby(['SeniorCitizen']).mean()

df[['Partner', 'Churn']].groupby(['Partner']).mean()

df[['Dependents', 'Churn']].groupby(['Dependents']).mean()

df[['PaperlessBilling', 'Churn']].groupby(['PaperlessBilling']).mean()

df[['PhoneService', 'Churn']].groupby(['PhoneService']).mean()

# Get all non-binary catagorical variables
non_bin_cat_col = [i for i in cat_cols if i not in bin_col ]
non_bin_cat_col

"""Now we Inspect our other catagorical value."""

#For Internet Service
sns.countplot(x = "InternetService", data = df)

# Impact on churn value
df[['InternetService', 'Churn']].groupby('InternetService').mean().sort_values(by = 'Churn', ascending=False)

"""Fiber Optics Internet Service has highst Churn Rate."""

df[['MonthlyCharges', 'InternetService']].groupby('InternetService').mean().sort_values(by = 'MonthlyCharges')

"""We Also Seen that Monthly Charge for Fiber Optic connection is higher then other two connection."""

#For Internet Service
sns.countplot(x = "MultipleLines", data = df)

# Impact on churn value
df[['MultipleLines', 'Churn']].groupby('MultipleLines').mean().sort_values(by = 'Churn', ascending=False)

"""We Seen that People with MultipleLines has highst Churn Rate

Now we will see the Internet releated features
"""

fig, axes = plt.subplots(2,3, figsize = (12,10), sharey = True)
plt.suptitle('Customer Distribution Across Internet Services')
sns.countplot(x='OnlineSecurity', data = df, ax=axes[0,0], order = df['OnlineSecurity'].value_counts().index)
sns.countplot(x='OnlineBackup', data = df, ax=axes[0,1], order = df['OnlineBackup'].value_counts().index)
sns.countplot(x='DeviceProtection', data = df, ax=axes[0,2], order = df['DeviceProtection'].value_counts().index)
sns.countplot(x='TechSupport', data = df, ax=axes[1,0], order = df['TechSupport'].value_counts().index)
sns.countplot(x='StreamingTV', data = df, ax=axes[1,1], order = df['StreamingTV'].value_counts().index)
sns.countplot(x='StreamingMovies', data = df, ax=axes[1,2], order = df['StreamingMovies'].value_counts().index)

"""Now we will check it out that, does these all featuers create any impact on our Churn rate"""

df[['OnlineSecurity', 'Churn']].groupby('OnlineSecurity').mean().sort_values(by='OnlineSecurity')

df[['DeviceProtection', 'Churn']].groupby('DeviceProtection').mean().sort_values(by='DeviceProtection')

df[['OnlineBackup', 'Churn']].groupby('OnlineBackup').mean().sort_values(by='OnlineBackup')

df[['TechSupport', 'Churn']].groupby('TechSupport').mean().sort_values(by='TechSupport')

df[['StreamingTV', 'Churn']].groupby('StreamingTV').mean().sort_values(by='StreamingTV')

df[['StreamingMovies', 'Churn']].groupby('StreamingMovies').mean().sort_values(by='StreamingMovies')

"""So, After Analysis we seen thatthese internet services have a high churn rate

Now We will Analyze Contract & Payment Method
"""

sns.countplot(x = 'Contract', data = df)
plt.title('Customers by Contract Type')

df[['Contract', 'Churn']].groupby('Contract').mean()

"""Customers with shorter contract have churn rate more"""

plt.figure(figsize = (8,6))
sns.countplot(x = 'PaymentMethod', data = df, order = df['PaymentMethod'].value_counts().index)
plt.title('Customers Different Types Payment Method')

df[['PaymentMethod', 'Churn']].groupby('PaymentMethod').mean().sort_values(by = 'Churn')

"""customers who pay electronic check are more likely to churn and also this payment method is most common among the costumers.

Let's Check Continues Columns
"""

num_cols = []

for col in df.columns:
    if df[col].dtype.kind in 'iufc':
        num_cols.append(col)
num_cols

"""Here we will deal with tenure & MonthlyCharges"""

# Working with Tenure
sns.displot(data = df, x = "tenure", hue = "Churn", kind = "kde")
plt.title('Tenure vs Churn Value')

"""Customers with lower tenure tend to churn more and vice-versa."""

# wORKING Monthly Charges
sns.displot(data = df, x= 'MonthlyCharges', hue = 'Churn', kind = "kde")
plt.title('Monthly Charges vs Churn Value')

"""As the monthly charges go up customers tend to churn more."""

df[['MonthlyCharges', 'Churn', 'tenure']].groupby('Churn').mean()

df.columns

"""After EDA we seen that for our Model building and prediction every Feature of Columns are so important for us except customerID. So we will only Drop these Columns from our Dataset. We also need to drop Gender & TotalCharges"""

df.drop("customerID", axis=1, inplace = True)
df.drop("gender",axis=1,inplace = True)
df.drop("TotalCharges",axis=1,inplace = True)

# Extract catagorical features
cat_features = [i for i in df.columns if df[i].dtype == 'object']
cat_features

"""## **Data Preprocessing**

OneHotEncoding the Catagorical Features
"""

encoded_df = pd.get_dummies(df, columns = cat_features, drop_first = True)

"""Scaling"""

scaler = MinMaxScaler()

temp_1 = scaler.fit_transform(df[["tenure"]])
temp_2 = scaler.fit_transform(df[["MonthlyCharges"]])

# Replacing the original cols with scaled ones
encoded_df['tenure'] = temp_1
encoded_df['MonthlyCharges'] = temp_2

"""Treatment of Imbalance Data using UpSampling Techniques

We Already Know that our Churn Value has in Imbalance conditions
Let's Check it again
"""

sns.countplot(x = "Churn", data = df)
plt.title('Distribution of Target Before Upsampling')

churned = encoded_df[encoded_df['Churn']==1]
not_churned = encoded_df[encoded_df['Churn'] == 0]

churned_upsampled = resample(churned,
                             replace = True,
                             n_samples = len(not_churned),
                             random_state = 1)

# Combining the upsampled data
final_df = pd.concat([churned_upsampled, not_churned])
sns.countplot(x = "Churn", data = final_df)
plt.title("Distribution of Target After Upsampling")

final_df.head(2)

"""## **Model Building & Testing**

**Spliting Dataset**
"""

x = final_df.drop("Churn", axis = 1) #Independet Variable
y = final_df["Churn"] #Dependent Variable / Target Variable

x_train,x_test,y_train,y_test = train_test_split(x,y, random_state = 1, test_size = 0.2)

"""**Model Bulding**

For Model Building we will try 4 different Model. They are:

1. ADABoost Classifier
2. XGBoost Classifier
3. RandomForest Classifier
3. DecisionTree Classifier

### **Adaboost**
"""

ada_class = AdaBoostClassifier()

ada_class.fit(x_train,y_train)

# Accuracy score on training data
ada_train_pred = ada_class.predict(x_train)
ada_acc_train = accuracy_score(ada_train_pred, y_train)
print("Accuracy score on trianing data:",ada_acc_train)

# Accurcy on test data
ada_test_pred = ada_class.predict(x_test)
ada_acc_test = accuracy_score(ada_test_pred, y_test)
print("Accuracy score on test data:",ada_acc_test)

ada_recall = recall_score(y_test,ada_test_pred)
ada_precision = precision_score(y_test, ada_test_pred)
print("AdaBoost Classifier model's metrics:\n")
print("Accuracy on Training Data:", round(ada_acc_train*100, 2),"%")
print("Accuracy on Test Data:", round(ada_acc_test*100,2),"%")
print("Recall Score:", round(ada_recall,2))
print("Precision Score:", round(ada_precision,2))

confusion_matrix = metrics.confusion_matrix(y_test, ada_test_pred)
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix,
                                            display_labels = ['Negative', 'Positive'])
cm_display.plot()
plt.title('Confusion Matrix: ADABoost Classifier')
plt.show()

#ROC and AOC CURVE Visualization for KNN
ada_prob = ada_class.predict_proba(x_test)[:,1]
ada_AOC = metrics.roc_auc_score(y_test,ada_prob)
print("AOC SCORE: ",ada_AOC)

f_pr,t_pr,thresholdvalues = metrics.roc_curve(y_test,ada_test_pred)
plt.plot([0,1],[0,1],color='red',linestyle='--')
print("XGBooster Classifier (area= " +str(ada_AOC)+")")
plt.plot(f_pr,t_pr)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ADABoost AUC Score")
plt.show()

"""### **XGBoost**"""

xgb_model = XGBClassifier()

xgb_model.fit(x_train, y_train)

# Accuracy score on training data
xgb_train_pred = xgb_model.predict(x_train)
xgb_acc_train = accuracy_score(xgb_train_pred, y_train)
print("Accuracy score on trianing data:",xgb_acc_train)

# Accuracy score on test data
xgb_test_pred = xgb_model.predict(x_test)
xgb_acc_test = accuracy_score(xgb_test_pred, y_test)
print("Accuracy score on testing data:",xgb_acc_test)

xgb_recall = recall_score(y_test,xgb_test_pred)
xgb_precision = precision_score(y_test, xgb_test_pred)
print("XGBClassification model's metrics:\n")
print("Accuracy on Training Data:", round(xgb_acc_train*100, 2),"%")
print("Accuracy on Test Data:", round(xgb_acc_test*100,2),"%")
print("Recall Score:", round(xgb_recall,2))
print("Precision Score:", round(xgb_precision,2))

confusion_matrix = metrics.confusion_matrix(y_test, xgb_test_pred)
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix,
                                            display_labels = ['Negative', 'Positive'])
cm_display.plot()
plt.title('Confusion Matrix: XGBoost Classifier')
plt.show()

#ROC and AOC CURVE Visualization for KNN
xgb_prob = xgb_model.predict_proba(x_test)[:,1]
xgb_AOC = metrics.roc_auc_score(y_test,xgb_prob)
print("AUzC SCORE: ",xgb_AOC)

f_pr,t_pr,thresholdvalues = metrics.roc_curve(y_test,xgb_test_pred)
plt.plot([0,1],[0,1],color='green',linestyle='--')
print("XGBooster Classifier (area= " +str(xgb_AOC)+")")
plt.plot(f_pr,t_pr)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.show()

"""### **RandomForest Classifier**"""

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()

rf.fit(x_train,y_train)

# Accuracy score on training data
rf_train_pred = rf.predict(x_train)
rf_acc_train = accuracy_score(rf_train_pred, y_train)
print("Accuracy score on trianing data:",rf_acc_train)

# Accuracy score on test data
rf_test_pred = rf.predict(x_test)
rf_acc_test = accuracy_score(rf_test_pred, y_test)
print("Accuracy score on testing data:",rf_acc_test)

rf_recall = recall_score(y_test,rf_test_pred)
rf_precision = precision_score(y_test, rf_test_pred)
print("XGBClassification model's metrics:\n")
print("Accuracy on Training Data:", round(rf_acc_train*100, 2),"%")
print("Accuracy on Test Data:", round(rf_acc_test*100,2),"%")
print("Recall Score:", round(rf_recall,2))
print("Precision Score:", round(rf_precision,2))

confusion_matrix = metrics.confusion_matrix(y_test, rf_test_pred)
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix,
                                            display_labels = ['Negative', 'Positive'])
cm_display.plot()
plt.title('Confusion Matrix: RandomForest Classifier')
plt.show()

#AOC CURVE DecisionTree
rf_prob = rf.predict_proba(x_test)[:,1]
rf_AOC = metrics.roc_auc_score(y_test,rf_test_pred)
print("AUC SCORE: ",rf_AOC)

f_pr,t_pr,thresholdvalues = metrics.roc_curve(y_test,rf_test_pred)
plt.plot([0,1],[0,1],color='yellow',linestyle='--')
print("RandommForest Classifier (area= " +str(rf_AOC)+")")
plt.plot(f_pr,t_pr)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.show()

"""### **Decision Tree**"""

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier()

dt.fit(x_train,y_train)

# Accuracy score on training data
dt_train_pred = dt.predict(x_train)
dt_acc_train = accuracy_score(dt_train_pred, y_train)
print("Accuracy score on trianing data:",dt_acc_train)

# Accuracy score on test data
dt_test_pred = dt.predict(x_test)
dt_acc_test = accuracy_score(dt_test_pred, y_test)
print("Accuracy score on testing data:",dt_acc_test)

dt_recall = recall_score(y_test,dt_test_pred)
dt_precision = precision_score(y_test, dt_test_pred)
print("XGBClassification model's metrics:\n")
print("Accuracy on Training Data:", round(dt_acc_train*100, 2),"%")
print("Accuracy on Test Data:", round(dt_acc_test*100,2),"%")
print("Recall Score:", round(dt_recall,2))
print("Precision Score:", round(dt_precision,2))

confusion_matrix = metrics.confusion_matrix(y_test, dt_test_pred)
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix,
                                            display_labels = ['Negative', 'Positive'])
cm_display.plot()
plt.title('Confusion Matrix: DecisionTree Classifier')
plt.show()

#AUC CURVE DecisionTree
dt_prob = dt.predict_proba(x_test)[:,1]
dt_AUC = metrics.roc_auc_score(y_test,dt_test_pred)
print("AUC SCORE: ",dt_AUC)

f_pr,t_pr,thresholdvalues = metrics.roc_curve(y_test,dt_test_pred)
plt.plot([0,1],[0,1],color='purple',linestyle='--')
print("DecisionTree Classifier (area= " +str(dt_AUC)+")")
plt.plot(f_pr,t_pr)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.show()

# Sample data (replace this with your actual model results)
model_results = {
    'Model': ['ADABoost Classifier', 'XGBoost Classifer', 'RandomForest Classifier', 'DecisitionTree Classifier'],
    'Accuracy': [ada_acc_test, xgb_acc_test,rf_acc_test,dt_acc_test],
    'Precision': [ada_precision, xgb_precision, rf_precision, dt_precision],
    'Recall': [ada_recall, xgb_recall, rf_recall, dt_recall],
}

# Creating a DataFrame
results_df = pd.DataFrame(model_results)

# Display the results in a table
print(results_df)



"""# **Final Result making By Voting Classfier**"""

clf1 = AdaBoostClassifier()
clf2 = RandomForestClassifier()
clf3 = XGBClassifier()
clf4 = DecisionTreeClassifier()
eclf1 = VotingClassifier(estimators=[('abc', clf1), ('rfc', clf2), ('xgb', clf3),('dt',clf4)], voting='soft')
eclf1.fit(x_train, y_train)
predictions = eclf1.predict(x_test)
voting_accuracy = accuracy_score(y_test, predictions)
voting_recall = recall_score(y_test,predictions)
voting_precision = precision_score(y_test,predictions)
print("Final Accuracy: ", round(voting_accuracy*100,2),"%")
print("Final Recall_score: ", round(voting_recall,2))
print("Final Precision_score: ", round(voting_precision,2))

# Sample data (replace this with your actual model results)
model_results = {
    'Model': ['ADABoost Classifier', 'XGBoost Classifer', 'RandomForest Classifier', 'DecisitionTree Classifier',"Voting Classifier"],
    'Accuracy': [ada_acc_test, xgb_acc_test,rf_acc_test,dt_acc_test,voting_accuracy],
    'Precision': [ada_precision, xgb_precision, rf_precision, dt_precision,voting_precision],
    'Recall': [ada_recall, xgb_recall, rf_recall, dt_recall,voting_recall],
}

# Creating a DataFrame
results_df = pd.DataFrame(model_results)

# Display the results in a table
print(results_df)

# Sample model accuracies (replace with your actual accuracy values)
model_accuracies = [ada_acc_test,xgb_acc_test,rf_acc_test,dt_acc_test,voting_accuracy]
model = ["Adaboost Classifier","XGBoost Classifier","RandomForest Classifier","DecisionTreeClassifier","VotingClassifier"]
# Create a boxplot using Seaborn
plt.figure(figsize=(8, 6))
sns.boxplot(data=model_accuracies)
plt.title('Model Accuracies')
plt.ylabel("Accuracy")
plt.xlabel(model)
plt.show()

# model check using ADABoost
d = {'Actual Status': y_test, 'Predicted Status': ada_test_pred}
pred_data = pd.DataFrame(d)
pred_data

# model check using XGBBoost
d = {'Actual Status': y_test, 'Predicted Status': xgb_test_pred}
pred_data = pd.DataFrame(d)
pred_data

# model check using RandomForest
d = {'Actual Status': y_test, 'Predicted Status': rf_test_pred}
pred_data = pd.DataFrame(d)
pred_data

# model check using DecisionTree
d = {'Actual Status': y_test, 'Predicted Status': dt_test_pred}
pred_data = pd.DataFrame(d)
pred_data

"""So, We can See that, Our 3 Models are now well trained & tested to Predict Customer Churn with high accuracy rate except ADABoost Classifier."""